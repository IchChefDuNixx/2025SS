{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "isInteractiveWindowMessageCell": true
   },
   "source": [
    "Connected to sep28k (Python 3.11.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Gradient Descent for Linear Regression\n",
    " You can find the definitions for linear regression and the training data here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Training data\n",
    " | x   |  y  |\n",
    " |:----|:---:|\n",
    " | 1   |  1  |\n",
    " | 2   |  3  |\n",
    " | 4   |  3  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Feature extractor\n",
    " $\\phi(x) = [1, x]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Weights\n",
    " $\\mathbf{w} = [w_1, w_2]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Score\n",
    " $  f_{\\mathbf{w}}(x) = \\mathbf{w} \\cdot \\phi(x) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Squared Loss\n",
    " $ \\text{Loss}(x, y, \\mathbf{w}) = (f_{\\mathbf{w}}(x) - y)^2 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Gradient of the Squared Loss\n",
    " $ \\nabla_{\\mathbf{w}} \\text{TrainLoss}(\\mathbf{w}) = \\frac{1}{|\\mathcal{D}_{\\text{train}}|} \\sum_{(x,y) \\in \\mathcal{D}_{train}} \\underbrace{2 (\\underbrace{\\textcolor{red}{\\mathbf{w} \\cdot \\phi(x)} - \\textcolor{green}{y}}_{\\text{\\textcolor{red}{prediction}} - \\text{\\textcolor{green}{target}}})}_{\\text{derivative of outer function}} \\cdot \\underbrace{\\phi(x)}_{\\text{derivative of inner function}} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Gradient Descent\n",
    " ```\n",
    " Initialize w = [0, ..., 0]\n",
    " For t = 1, ..., T  (epochs)\n",
    "   For (x,y) ∊ D[train]\n",
    "     w ← w - η ･ ∇Loss(x, y, w)\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 1. Use the data provided below to implement a class called LinearRegression\n",
    " The class should have a method called `fit` that performs training using gradient descent.\n",
    " Also think of implementing your feature extraction $\\phi$ as a method.\n",
    " You can implement everything in the first section without any python package outside of the standard library.\n",
    " but I would recommend using `numpy` for access to the `numpy.dot` method for easy access\n",
    " to dot product computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class LinearRegression:\n",
    "    def __init__(self) -> None:\n",
    "        self.w = np.zeros((2,))\n",
    "\n",
    "    def phi(self, x):\n",
    "        pass\n",
    "\n",
    "    def score(self, x):\n",
    "        pass\n",
    "\n",
    "    def linear_loss(self, y, y_hat):\n",
    "        pass\n",
    "\n",
    "    def squared_loss(self, y, y_hat):\n",
    "        pass\n",
    "\n",
    "    def grad_linear_loss(self, y, y_hat):\n",
    "        pass\n",
    "\n",
    "    def grad_squared_loss(self, x, y, y_hat):\n",
    "        pass\n",
    "\n",
    "    def fit(self, data, epochs, lr=0.1):\n",
    "        for epoch in range(epochs):\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO this should be working in the end\n",
    "reg = LinearRegression()\n",
    "data = np.array([[1, 1], [2, 3], [4, 3]])\n",
    "reg.fit(data, 1, lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 1.1 Implement Linear Loss\n",
    " Add a method to your class that computes the linear loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 1.2 Implement Squared Loss\n",
    " Add a method to your class that computes the squared loss\n",
    " ### 1.3 Implement the Gradient computation for both losses\n",
    " Implement the functionality to compute the gradient for both functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 1.4 Implement Gradient Descent that can use both loss functions\n",
    " Now implement the core of what we did in the lectures.\n",
    " Iterate over the number of epochs and inside this loop over the data.\n",
    " Keep track of the loss and the gradient for the examples. Once you\n",
    " computed it for the whole data, compute the gradient update as per the formulas\n",
    " and the algorithm from the lectures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 1.4 Run the optimization using both\n",
    " ### 1.5. Create the functionality to keep track of the loss during training\n",
    " Calculate the loss and store it in a dictionary or list that is part of your class.\n",
    " In a dictionary, the keys would be the epochs. In a list, you could just add an item for\n",
    " every epoch. The index location of the calculated loss + 1 would indicate the training epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 2. Plot the loss curves\n",
    " Install two libraries for plotting.\n",
    " Seaborn is a more intuitive and simpler interface to the matplotlib functionality.\n",
    " Sometimes you need to adapt things using matplotlib.\n",
    " ```bash\n",
    " pip install seaborn\n",
    " pip install matplotlib\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 2.1 Create a more realistic example using sklearn\n",
    " Use `sklearn.datasets.make_regression` to create a toy dataset.\n",
    " #### Installing scikit Learn\n",
    " ```bash\n",
    " pip install scikit-learn\n",
    " ```python\n",
    " from sklearn import datasets\n",
    " X, y = datasets.make_regression(100, 1,) # 100 samples, 1 feature, no noise\n",
    " ```\n",
    " Run your own regression model and check for runtimes and runtime differences\n",
    " Also keep track of the loss and plot it.\n",
    " Add a bit of noise to the create process of the data. Check the documentation\n",
    " of the function on how to do that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 2.2. Make a scatter plot of the data and plot the regression line\n",
    " Using the data you crated, please plot the data and add the regression line\n",
    " based on the weights $\\mathbf{w}$ you learned from the data.\n",
    " Is it a good fit?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sep28k",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
